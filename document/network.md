## 목차

<!-- 목차 -->
- [목차](#목차)
- [OSI 7계층](#osi-7계층)
- [TCP/IP 4계층](#tcpip-4계층)
- [TCP vs UDP](#tcp-vs-udp)
- [TCP 연결 과정](#tcp-연결-과정)
- [연결은 3단계인데 종료는 4단계인 이유](#연결은-3단계인데-종료는-4단계인-이유)
- [만약 수신측에서 FIN 패킷을 보내기 전에 전송했던 패킷에서 문제가 발생하는 경우](#만약-수신측에서-fin-패킷을-보내기-전에-전송했던-패킷에서-문제가-발생하는-경우)
- [Block vs Non Block](#block-vs-non-block)
- [HTTP 버전](#http-버전)
- [CORS](#cors)
- [CSRF](#csrf)
- [XSS](#xss)
- [XSS vs CSRF](#xss-vs-csrf)
- [XSS 종류](#xss-종류)
- [로드 밸런싱](#로드-밸런싱)
- [웹 브라우저의 검색 과정](#웹-브라우저의-검색-과정)
- [HTTP vs HTTPS](#http-vs-https)
- [SSL](#ssl)
- [Key](#key)
- [SSL 동작 과정](#ssl-동작-과정)
- [GET vs POST](#get-vs-post)
- [JWT](#jwt)
- [HTTP 는 TCP 인가 UDP 인가?](#http-는-tcp-인가-udp-인가)
- [HTTP 응답코드](#http-응답코드)
- [쿠키](#쿠키)
- [세션](#세션)
- [쿠키 vs 세션](#쿠키-vs-세션)
- [Post vs Put vs Patch](#post-vs-put-vs-patch)
- [HTTP 캐시](#http-캐시)
- [NginX](#nginx)
- [무중단 배포 구현 및 종류](#무중단-배포-구현-및-종류)
<!-- /목차 -->

## OSI 7계층
* 물리 계층(Physical Layer)
    - 데이터를 전송하는 역할만 담당
    - 전송 단위 : 비트(Bit)
    - 대표적인 예 : 리피터와 허브
* 데이터링크 계층(DataLink Layer)
    - 신뢰성있는 통신을 위한 오류제어 및 흐름제어 역할
    - 전송 단위 : 프레임(Frame)
    - 대표적인 예 : 브리지와 스위치
* 네트워크 계층(Network Layer)
    - 목적지를 보고 어떠한 경로로 보낼지 결정하는 라우팅 역할
    - 전송 단위 : 패킷(Packet)
    - 대표적인 예 : 라우터
* 전송 계층(Transport Layer)
    - 종단 간 통신을 담당
    - 종단 간 오류제어 및 흐름제어
    - 대표적인 예 : TCP 와 UDP
* 세션 계층(Session Layer)
    - 통신간의 세션 연결과 동기화를 담당
    - 즉, 데이터 통신의 논리적 연결을 말함
* 표현 계층(Presentation Layer)
    - 응용 계층에서 데이터를 이해할 수 있도록 변환 또는 압축
* 응용 계층(Application Layer)
    - 사용자 인터페이스를 지원
    - HTTP 프로토콜 사용

## TCP/IP 4계층
* 대부분의 데이터 통신이 TCP 와 IP 기반으로 이루어져 있기 때문에 인터넷 프로토콜 그 자체를 표현하는 용어
* 사실상, 인터넷 프로토콜을 대표하는 용어로 사용된다.
* 네트워크 엑세스 계층 (1계층)
    - OSI 7계층에서 물리 계층과 데이터링크 계층
    - 물리적 연결을 지원 -> 물리적으로 데이터가 네트워크를 통해 어떻게 전송되는지 정의
    - 물리적인 주소로 MAC 을 사용
    - MAC : 기기 별로 갖고 잇는 물리적 주소
* 인터넷 계층 (2계층)
    - OSI 7계층에서 네트워크 계층
    - 노드 간의 패킷 전송 기능과 라우팅 기능을 담당
    - 전송 계층으로 받은 데이터에 IP 헤더를 붙여 IP 패킷 생성
    - 라우터가 IP 헤더를 해석해서 IP 패킷에 라우팅
    - 프로토콜 : IP, ARP, RARP
* 전송 계층 (3계층)
    - OSI 7계층에서 전송 계층
    - 신뢰성 있는 전송 기능 제공
    - 프로토콜 : TCP, UDP
* 응용 계층 (4계층)
    - OSI 7계층에서 세션 계층, 표현 계층, 응용 계층
    - 사용자 인터페이스 구현
    - 프로토콜 : FTP, HTTP, SSH

## TCP vs UDP
* TCP 와 UDP 는 전송 계층에서 사용하는 프로토콜
* TCP
    - 연결형 서비스로 IP 와 함께 사용되는 프로토콜
    - IP 가 패킷 전송을 처리한다면 TCP 는 오류제어 및 흐름제어 역할을 한다.
    - 3-way Handshake 를 통한 연결과정을 거치기 때문에 안정적인 데이터 전송에 유리
    - 연결과정 때문에 시간이 오래 걸린다.
    - http 통신이나 파일전송처럼 속도보다는 신뢰성이 더 중요한 경우에 사용
* UDP
    - 비연결형 서비스
    - 연결 과정이 없고 헤더가 간단해서 빠름
    - Checksum 필드를 통해서 최소한의 오류만 검출하기 때문에 신뢰성이 낮음
    - 신뢰성보다는 스트리밍 같이 실시간 서비스에 더 적합하다.

## TCP 연결 과정
* TCP 는 정확한 데이터 전송을 보장해야 한다.
* 따라서, 통신하기 전에 연결을 맺는 과정이 있는데 이를 3-way HandShake 과정이라 한다.
* 연결 과정
    - 송신 측에서 수신 측으로 연결 요청을 위한 SYN 패킷 전달
    - 수신 측에서 SYN 패킷에 대한 ACK 패킷과 연결 요청을 위한 SYN 패킷 전달
    - 수신 측의 SYN 패킷에 대한 ACK 응답
* 연결 종료 과정
    - 송신 측에서 FIN 패킷 전달
    - 수신 측에서 FIN 패킷에 대한 ACK 응답
    - 수신 측에서도 통신이 끝나면 FIN 패킷 전달
    - 수신 측의 FIN 패킷을 받고 TIME_WAIT 를 가진 후 ACK 응답
* SYN : Synchronize Sequence Number, 연결 요청 메시지
* ACK : Acknowledgement number

## 연결은 3단계인데 종료는 4단계인 이유
* 송신측에서 데이터 전송을 마쳤다고 하더라도 서버는 아직 보낼 데이터가 남아있을 수 있다.
* 따라서, FIN 에 대한 ACK 만 보내고 자신의 데이터 통신이 끝날 때 까지 기다린 후, 모든 전송이 끝나면 FIN 메세지를 보낸다.

## 만약 수신측에서 FIN 패킷을 보내기 전에 전송했던 패킷에서 문제가 발생하는 경우
* 송신측이 수신측으로부터 FIN 플래그를 수신하더라도 일정시간 동안 대기하는 시간을 가지면서 해결
* 이를 TIME_WAIT 라 한다.
* 즉, 아직 서버로부터 못 받은 데이터 있을 것을 대비하여 일정시간동안 세션을 남긴다.

## Block vs Non Block
* I/O 작업은 커널 레벨에서만 수행할 수 있다.
* 따라서 프로세스 또는 스레드는 커널에 I/O 요청을 보내야 한다.
* Block
    - 프로세스가 커널에 I/O 요청을 하는 함수를 호출하고 커널이 작업을 완료하면 작업 결과를 반환 받는다.
    - I/O 작업이 진행되는 동안 요청을 보낸 프로세스 또는 스레드는 자신의 작업을 중단해야해서 자원 낭비가 심하다.
* Non Block
    - I/O 작업이 진행되는 동안에도 프로세스 또는 스레드 작업을 중지하지 않는다.
    - 호출된 함수가 바로 리턴되어서 호출한 함수에게 제어권을 넘겨주고 호출한 함수가 다른 일을 할 수 있는 기회를 준다.

## HTTP 버전
* HTTP/0.9
    - 아주 단순하게 GET 통신만 가능
    - 헤더가 존재하지 없기 때문에 전송은 HTML 문서로만 가능하고 다른 유형은 전송할 수 없다.
    - 상태 혹은 오류 코드가 없음
* HTTP/1.0
    - 상태코드가 응답 값 시작 부분에 포함
    - 헤더가 요청과 응답 모두에 추가되어 프로토콜의 확장이 가능해졌다.
    - Content-Type 의 도움으로 HTML 파일 이외에 다른 문서들도 전송이 가능해짐
    - POST, HEAD 메서드가 추가되었다.
    - Connection 하나로 요청과 응답 각각 하나씩만 처리할 수 있다. -> 매번 새로운 요청마다 커넥션을 새로 해야하기 때문에 비용이 증가한다.
* Http 1.1 vs Http 2.0
    - HTTP/1.1
        - HTTP 의 첫 번째 표준 버전으로 OPTION, PUT, DELETE, TRACE 메서드가 추가되었다.
        - Persistent Connection 도입
            - 요청과 응답이 끝나면 Connection 을 종료하지 않고 일정 시간(timeout) 동안 커넥션을 닫지 않는 방삭
        - Pipelining 기법 도입
            - 이전에는 A,B,C 요청이 있을 때 각 요청이 순서대로 응답을 받아야 다음 요청을 보냈다.
            - 이 기법을 도입하고 하나의 커넥션에서 응답을 기다리지않고 요청들만 먼저 보낸 후 그 순서에 맞춰 응답을 받는 방식
            - 문제점 : head of line blocking
                - A,B,C 요청을 보냈고 A 요청의 응답 시간은 100초, B 요청의 응답 시간은 2초라고 가정하자
                - B 요청은 빠르게 처리해서 응답할 수 있지만 A 요청이 오래걸리기 때문에 계속 기다리는 현상
        - Header 가 계속 중복되는 문제가 있음 (10개의 정보 중 하나만 바뀌어도 나머지는 매번 똑같은 정보를 보내야함 -> 낭비)
    - HTTP/2.0
      ![images](https://media.vlpt.us/images/taesunny/post/eddc9c22-7d46-4899-877c-f8ce751609d5/image.png)
      ![images](https://media.vlpt.us/images/taesunny/post/17fd473d-7e43-4e73-9bba-8f64ee3ef21d/image.png)
        - 기존에 text 형식으로 주고 받았던 방식 말고, 바이너리 포맷으로 인코딩된 계층을 사용한다.
        - Stream : 구성된 연결 내에서 전달되는 바이트의 양방향 흐름, 하나 이상의 메시지가 전달 가능하다.
        - Message : 논리적 요청 또는 응답 메시지에 매핑되는 프레임의 전체 시퀀스이다.
        - Frame
            - HTTP/2에서 통신의 최소 단위.
            - 각 최소 단위에는 하나의 프레임 헤더가 포함된다.
            - HEADERS Type Frame, DATA Type Frame 이 존재한다.
        - 헤더 중복 해결
            - 기존 헤더의 중복 문제를 해결함
            - Header Table 과 Huffman Encoding 을 사용하여 해결
            - 클라이언트와 서버는 각각 Header Table 을 관리하고 이전 요청과 동일한 필드는 table 의 index 만 보냄
            - 변경된 사항은 Huffman Encoding 을 사용하여 Header 크기를 경량화 시킴
                - Huffman Encoding : 주어진 문자열을 트리를 통해 2진수로 압축하는 알고리즘
        - HOL Blocking, head of line blocking 의 해결
          ![images](https://media.vlpt.us/images/taesunny/post/8ba0ec32-1e59-4ffc-a801-21502f44e8a4/image.png)
            - HTTP Pipelining 의 개선안으로 하나의 Connection 으로 동시에 여러 개의 메세지를 주고 받을 수 있다. (다중화)
            - TCP 연결 하나로 여러 요청과 응답들을 병렬적으로 보낼 수 있다.
            - 하나의 커넥션에서 여러 병렬 스트림(3개)이 존재 할 수 있다.
            - stream 이 뒤섞여서 전송 될 경우, stream number 를 이용해 수신측에서 재조합된다.
        - Stream Prioritization
            - 응답에 대한 우선순위를 정해 우선순위가 높을수록 응답을 빨리 한다.
        - Server Push
            - 서버가 클라이언트의 요청없이 응답을 보내는 방법
            - 예를들어 하나의 html 요청안에 css 와 jpg 파일이 있다고 가정하자.
            - 기존에는 html 요청을 하고 다시 css, jpg 를 요청해야했지만, 이제는 서버가 알아서 css, jpg 도 같이 응답해주는 것을 말함

## CORS
* Cross-Origin Resource Sharing 의 약자
* 도메인이나 포트가 다른 서버의 자원을 요청하는 메커니즘을 말한다.
* 동일 출처 정책때문에 CORS 같은 상황이 발생하면 외부 서버에 요청한 데이터를 브라우저에서 보안 목적으로 차단한다.
* 해결법
    - 서버에서 크로스 도메인 허용
    - 서버의 응답헤더에 Access-Control-Allow-Origin 을 추가하여 해결
* 동작 방법
    - Preflight (예비 요청)
        - OPTIONS 메서드를 이용해 서버로부터 지원 중인 메서드들을 내려받는다.
        - 서버에서 Access-Control-Allow-Origin 이 허용일 경우 OK 리턴
    - Simple Request
        - OK 이고 사용가능한 HTTP 메서드이면 API 호출
        - 서버에서 응답

## CSRF
* Cross Site Request Forgery 의 약자
* 사용자의 인증된 정보를 이용하여 수정, 삭제, 등록 등 악의적인 요청을 하는 것
* 대응 방안
    - 사용자 세션에 임의의 난수 값을 저장하고 사용자의 요청마다 해당 난수 값을 포함시켜서 전송
    - Spring Security 를 사용
        - 하지만 내가 설계한 Rest API 의 경우 csrf.disable() 로 CSRF 를 사용하지 않았다
        - 왜냐하면 Rest API 의 경우 stateless 하게 개발하기 때문에 사용자의 정보를 세션에 저장하지 않는다. -> 따라서 JWT 같은 토큰을 Cookie 에 저장하는게 아닌 이상 CSRF 취약점에 어느정도 안전하다
    - 요청의 도메인이 일치하는지 검증
    - SSL 적용

## XSS
* Cross-Site Scripting 의 약자
* 악의적인 스크립트를 삽입하여 해당 스크립트가 희생자 측에서 동작하도록 하여 악의적인 행위를 수행하는 취약점
* 즉, 사이트에 스크립트 코드를 삽입하는 공격 기법
* 웹 서버가 사용자로부터 입력 받은 값을 제대로 검사하지 않고 사용할 경우에 나타난다.
* 해커가 사용자의 정보를 탈취하거나 자동으로 비정상적인 기능을 수행할 수 있게 한다.
* 대응 방안
    - Script 문자 필터링 (클라이언트 단에서 유효성 검사)
    - XSS 방어 라이브러리
    - 웹 방화벽
    - 백엔드에서 XSS 필터를 구현

## XSS vs CSRF
* XSS
    - 사용자가 특정 웹 사이트를 신용하는 점을 노림
    - 즉, 공격자가 특정 웹 사이트에 스크립트를 삽입하면, 그 웹 사이트를 신용하는 사용자가 웹 사이트 방문 시 사용자의 정보를 탈취하거나 비정상적인 기능을 수행하게 함
    - 다시 말해서, 사이트 변조를 통해 클라이언트에게 악성 공격을 한다.
* CSRF
    - 사용자가 웹 사이트에 로그인한 상태에서 CSRF 코드가 삽입된 페이지를 열면 공격 대상이 되는 웹 사이트는 위조된 공격 명령이 믿을 수 있는 사용자로부터 발송된 것으로 판단하여 공격에 노출
    - 즉, CSRF 는 요청을 위조하여 사용자 권한을 이용을 사용하므로써 서버에 악성 공격을 한다.
* 가장 큰 차이점은 공격이 실행되는 위치이다.
* 즉, XSS 는 희생자 클라이언트 PC 에서 실행되며 사용자의 정보를 탈취하는 것이고, CSRF 는 위조된 요청을 서버에 보내어 서버단에서 스크립트가 실행된다.

## XSS 종류
* Stored XSS
    - DataBase 에 저장되어 지속적으로 활용
    - 공격자가 웹 서버에 악성 스크립트를 저장하면 사용자가 악성 스크립트가 삽입된 부분을 요청하여 클라이언트에서 동작
    - 게시판 쪽지 함 등 저장형 형태의 게시글에서 많이 사용됨
* Reflected XSS
    - DataBase 에 저장하는 것이 아닌 1회성이다.
    - 외부에 있는 악성 스크립트가 사용자 액션에 의해서 웹 서버로 전달되고 웹 서버에 악성 스크립트가 삽입되어 클라이언트에서 동작
    - 메일이나 쪽지 등에 악성 스크립트가 포함된 URL 을 보내고 사용자가 해당 URL 을 클릭하면 악의적인 스크립트가 실행된다.

## 로드 밸런싱
* 여러 대의 서버에 균등하게 트래픽을 분배시켜 서버의 부하를 분산시키는 기술
* 동작 과정
    - DNS 서버에 도메인에 대한 IP 주소가 아닌 도메인에 대한 부하 분산 장치(ex. NginX) IP 주소를 등록
    - 도메인을 검색하면 부하 분산 장치(ex. NginX) IP 로 이동하고
    - 부하 분산 장치(ex. NginX) 는 적절한 방식으로 균등하게 IP 주소를 반환
* 종류
    - L4
        - 전송 계층에서 진행하는 로드 밸런싱
        - IP, Port 기반으로 로드 밸런싱을 진행
        - 속도가 빠르나, 정교한 분배는 못한다.
    - L7
        - 응용 계층에서 진행하는 로드 밸런싱
        - Header 나 URL 등 애플리케이션 기반으로 로드 밸런싱
        - 정교한 분배가 가능하나 헤더 등 패킷을 까봐야하기 때문에 속도가 조금 느리다.
        - http 헤더나 쿠키를 분석해서 하기 때문에 빠른
* 알고리즘
    - Round Robin
        - 요청을 순서대로 균등하게 처리
    - Least Connection (최소 연결 방식)
        - 요청이 들어온 순간 Connection 개수가 가장 적은 곳에서 처리
        - 트래픽이 불규칙할 경우에 사용한다.
    - IP Hash
        - 클라이언트의 IP 와 서버를 매핑하여 처리
        - 사용자가 항상 동일한 서버로 연결된다.
    - Weight Round Robin
        - 가중치를 부여하고 가중치가 높은 순서대로 처리 -> 즉, 가중치가 높은 서버의 처리 용량을 결정
        - 서버의 성능이 서로 다른 경우에 주로 사용한다.
* Server side vs Client side
    - Server side
        - NginX 나 L4 스위치 등으로 하는 보통의 부하 분산
        - 서버에 요청하기 전에 스위치가 받아서 각 서버로 분산
        - 문제점
            - 로드 밸런서가 처리할 수 있는 요청 수에 한계가 있다.
            - 로드 밸런서를 세팅하는 설정이 어렵고 비용이 많이 들어간다
            - 로드 밸런서가 문제 생길 것을 대비해서 Active-StandBy 방식으로 이중화를 해놓긴 하지만 이 비싼 장비가 놀게 된다.
    - Client side
        - 클라이언트 자체가 요청을 전달하는데 필요한 서버를 결정한다.
        - 중간 스위치를 거치지 않고 바로 서버로 요청이 간다.
        - 스위치에서 하던 분산 역할을 클라이언트 소프트웨어에서 처리
        - 대표적으로 Spring Cloud 의 Ribbon
* 로드 밸런싱으로도 해결하지 못하는 경우 고려해야할 것
    - 캐싱, DB 다중화, MSA

## 웹 브라우저의 검색 과정
* 웹 브라우저에 URL 검색
* DNS 서버에서 IP 로 변환
    - DNS 서버란?
        - domain name server
        - DNS 를 이용하여 IP 주소를 인간이 기억하기 편한 언어체계로 변환하는 작업을 하는 서버
* HTTP 요청 메세지 생성 (HTTP 메서드, 호스트 등)
* TCP 커넥션 생성 (3-way Handshake)
* 서버는 전송된 정보를 받아서 HTTP 메세지 해석
* 이를 바탕으로 작업한 후 응답 메세지 생성
* 클라이언트로 전송
* TCP 커넥션 종료 (4-way HandShake)
* 결과를 웹 브라우저에 띄움

## HTTP vs HTTPS
* HTTP
    - 웹 상에서 클라이언트와 서버간의 요청/응답으로 정보를 주고 받을 수 있는 프로토콜
    - Stateless 한 특징, 응답 요청 후 바로 연결이 끊어진다.
* HTTPS
    - HTTP 에 보안을 강화한 프로토콜
    - 정보를 암호화해서 전송

## SSL
* HTTP 통신규약과 함께 사용되어 HTTP 통신 간의 보안을 높여주는 기술
* SSL 은 보안 계층이라는 독립적인 프로토콜 계층을 만들어서 응용 계층과 전송 계층사이에 속하게 된다.
* SSL 은 TCP 기반의 프로토콜이기 때문에 TCP 연결의 3-way Handshake 와 SSL 연결의 3-way Handshake 를 수행하게 된다.

## Key
* 대칭키 = 비밀키
    - 송신자와 수신자가 같은 키로 암호화와 복호화를 진행
    - 하나의 키로 암호화하고 그와 같은 키로 복호화를 진행하기 때문에 대칭키라고한다.
    - 또한 이 키는 외부에 노출되면 안되기 때문에 비밀키라고도 한다.
* 비대칭키 = 공개키
    - 송신자는 외부에 공개된 키(public key)로 암호화하여 송신하고 수신자는 개인키(private key)로 복호화한다.
    - 송신자와 수신자가 사용하는 키가 다르므로 비대칭키라고 한다.


## SSL 동작 과정
* 웹 서버의 정보와 공개키를 인증기관(CA : Certificate Authority)으로 전송
* 인증기관은 개인키(private key)를 가지고 웹 서버의 정보와 공개키를 암호화하고 웹 서버로 반환한다.
* 클라이언트가 웹 서버로 요청을 보내면 인증기관의 개인키로 암호화된 웹 서버의 정보와 공개키를 브라우저한테 보낸다.
* 브라우저는 이미 가지고 있는 인증기관의 공개키로 웹 서버한테 받은 웹 서버의 정보과 공개키를 복호화한다.
* 브라우저는 요청할 데이터를 암호화할 대칭키를 생성하고 인증서에서 꺼낸 웹 서버의 공개키로 대칭키를 암호화하여 웹 서버로 전송
* 웹 서버는 자신이 가지고 있는 개인키로 복호화하여 브라우저가 보낸 대칭키를 얻음
* 이제 대칭키를 통해서 데이터를 암호화하여 주고받음
* 정리
    - 실제 전송되는 데이터의 암호화는 대칭키
    - 키 교환에는 공개키 암호화를 사용

## GET vs POST
* GET
    - URI 를 통해 요청
    - 조회 용도로 사용되고, Body 가 비어있다.
    - 요청이 URI 에 다 드러남
* POST
    - Body 를 통해 요청
    - 보통 데이터를 생성하는 용도로 사용
    - content-type 에 Body 의 타입이 담김

## JWT
* Json Web Token 의 줄임말
* Json 형식의 데이터를 토큰화해서 호스트끼리 데이터를 교류하는 기술
* 토큰 내에 사용자의 정보가 포함되어 있기 때문에 토큰을 복호화하는 것만으로 사용자의 정보를 조회할 수 있어서 Database 에 접근할 필요가 없다.
* 따라서 성능 향상을 얻을 수 있다.
* 주의점
    - 토큰에 사용자의 정보를 포함하는 만큼 토큰이 탈취된다면 보안 측면에서는 문제가 될 수 있다.
    - 따라서 토큰에는 사용자의 중요한 비밀정보는 포함시키지 않는 것이 졿다.
    - 토큰 자체를 암호화하는 JWE 도 있다.
    - 포함되는 내용이 많아지게 되면 토큰의 길이도 그만큼 늘어나기 때문에 오버헤드의 위험이 있으므로 주의해야 한다.
* 구성
    - Header
        - 토큰의 타입과 알고리즘이 담긴다.
        - 알고리즘은 헤더를 암호화하는 것이 아니라, 시그니처를 해싱하기 위한 알고리즘을 지정하는 것
    - Payload
        - Claim 의 형태로 되어있는 데이터가 암호화됨 (Base64)
    - Signature
        - 헤더와 페이로드의 값을 각각 Base64 로 인코딩하고, 인코딩한 값을 비밀키를 이용해 헤더에서 정의한 알고리즘으로 해싱하고 이 값을 다시 Base64 로 인코딩하여 생성
        - 비밀키가 노출되면 Claim 이 노출될 수 있으므로 비밀키가 노출되지 않도록 유의

## HTTP 는 TCP 인가 UDP 인가?
* HTTP 3버전 이전까지는 TCP 기반
    - 신뢰할 수 있는 전송방식만 제공하기 때문
* HTTP 3버전 이후부터는 UDP
    - UDP 를 커스텀하여 TCP 처럼 동작하도록 할 수 있고, 더 빠르기 때문에
* 참고
    - 스트리밍 서비스는 HTTP 프로토콜이 아닌 응용 계층의 RTP(RealTime Transport) 프로토콜 사용 -> UDP

## HTTP 응답코드
* 2XX : 성공
* 3XX : 리다이렉션 완료
* 400 : BadRequest
    - 사용자가 잘못된 요청을 했을 경우 (파라미터가 잘못되었거나 유효성 검사 실패)
* 404 : NotFound
    - 요청 URL 에 해당 자원이 존재하지 않음
* 403 : Forbidden
    - 해당 자원에 접근 권한이 없음
* 401 : Unauthorized
    - 사용자 인증이 되지 않음
* 5XX : 서버 오류

## 쿠키
* 사용자가 어떤 웹 사이트를 방문할 때 생성되는 정보를 담은 임시파일
* 서버가 브라우저에 저장하는 데이터
* 누군가가 임의로 고치거나 지울 수 있어서 보안에 취약
* 동작 순서
    - 클라이언트가 웹 서버에 요청
    - 웹 서버에서 쿠키 생성 후 응답
    - 클라이언트는 쿠키를 가지고 있다가 서버에 요청할 때 함께 쿠기 전송

## 세션
* 일정 시간동안 같은 사용자로부터 들어오는 요구사항을 하나로 보고 그걸 유지시키는 기술
* 클라이언트마다 세션 아이디를 부여해서 세션아이디로 클라이언트를 구분하여 서비스 제공
* 동작 순서
    - 클라이언트가 웹 서버로 요청
    - 웹 서버로 접근한 클라이언트의 Request Header 필드인 Cookie 를 확인해 클라이언트가 해당 세션 아이디를 보내왔는지 확인
    - 세션 아이디가 존재하지 않으면 세션 아이디를 생성해서 반환
    - 서버에서 반환해준 세션 아이디를 쿠키에 담아서 서버로 전송

## 쿠키 vs 세션
* 쿠키는 브라우저에서, 세션은 서버에서 관리
* 쿠키는 보안에 취약하고, 세션은 쿠키에 비해 보안이 높으나 서버에서 생성하여 관리하므로 서버에 부담이 간다.
* 해결책
    - JWT

## Post vs Put vs Patch
* Post
    - 요청 본문의 유형은 Content-Type 헤더로 나타냅니다.
    - 멱등성 보장 x
    - 요청 본문(body)에 데이터를 담아서 보낸다.
* Put
    - 요청 페이로드를 사용해 새로운 리소스를 생성하거나, 대상 리소스를 나타내는 데이터를 대체합니다.
    - 멱등성 보장
* Patch
    - 리소스의 부분적인 수정을 할 때에 사용
    - HTTP PUT 메소드는 문서 전체의 완전한 교체만을 허용한다.
    - 반면 PATCH 메소드는 PUT 메소드와 달리 멱등성을 가지지 않는데, 이는 동일한 patch 요청이 다른 결과를 야기할 수도 있음을 뜻한다.

## HTTP 캐시
* Rest api 도 Cache 기능을 사용할 수 있다.
* 캐시를 설정하면 Api 속도가 증가되고 사용자 입장에서 네트워크 트래픽을 줄일 수 있다.
* 응답 헤더에 어떻게 값을 넣느냐에 따라 다르게 동작한다.
* Cache Control + Expire
    ```text
  Response Header
      cache-control : public, max-age=31536000
    ```
    - max-age 시간동안 브라우저가 캐시를 해도 무방하다고 알려주는 방식
    - api 의 경우 언제 새로운 데이터가 포함될지 모르기 때문에 이 방식을 사용할 수 없다.
* Last Modified
    ```text
  Last-Modified : Mon, 03 Jan 2011 17:45:57 GMT
    ```
    - api 의 내용이 마지막으로 변경된 시간을 응답으로 주게되면 브라우저는 다음에 동일한 api 를 호출할 때 아래와 같은 요청 헤더를 추가해서 보낸다.
    ```text
  if-modified-since : Mon, 03 Jan 2011 17:45:57 GMT
    ```
    - 그럼 api 핸들러에서 마지막으로 변경된 시간을 체크해서 아직 안바뀐 경우 304 상태 코드르르 반환하여 브라우저가 캐시를 사용하게 된다.
    - 만약 DataBase 에서 마지막 변경 시간을 관리한다면 이 방식을 사용하면 안된다.
* ETag
    - Last-Modified 방식과 거의 동일
    - 시간 대신에 Hash 값을 사용한다는 측면에서 다르다.
    - 응답 데이터의 MD5 Hash 를 보통 사용하며 Last-Modified 보다 좀 더 유연하게 적용할 수 있다.
    ```text
  ETag : "15f0fff99ed5aae4edffdd6496d7131f"
    ```
    - 응답에 다음과 같은 ETag 헤더를 추가하면 다음 동일한 api 를 부르면 아래와 같은 요청헤더에 체크하는 헤더가 추가 된다.
    ```text
  if-none-match : "15f0fff99ed5aae4edffdd6496d7131f"
    ```
    - 서버에서 같은 ETag 를 가지고 있다면 304 반환
* 참고
    - Last-Modified 와 ETag 만 api 에 적용 가능하다.
    - redis 나 memcached 로 하는 것도 좋지만 http 캐시로 부하를 줄여보는 것도 좋다.
    - Database 부하를 줄일 수 있을 뿐 아니라 응답 데이터를 다시 받아오지 않아도 돼서 api 속도를 개선한다.

## NginX
* 경량 웹 서버
* 클라이언트로부터 요청을 받았을 때 요청에 맞는 정적 파일을 응답해주는 HTTP Web Server 로 활용되고,
* Reverse Proxy Server 로 활용하여 WAS 서버의 부하를 줄일 수 있는 로드 밸런서 역할로 활용되기도 한다.
* 특징
    - Event-Driven 구조로 동작하기 때문에 한 개 또는 고정된 프로세스만 생성하여 사용하고 비동기 방식으로 요청들을 동시(Concurrency)에 처리할 수 있다.
    - 요청마다 새로운 프로세스와 스레드를 생성하지 않기 때문에 생성 비용이 존재하지 않고 적은 자원으로 효율적인 운용 가능 -> 대용량 처리에 적합
    - 커넥션을 전부 이벤트 핸들러를 통해 비동기 방식으로 처리
    - 동작 과정
        - 사전에 서버 개발자가 정한 스레드 개수를 생성하고 해당 자원만을 가지고 HTTP 요청을 처리
        - Event-Driven 구조로 동작하기 때문에 요청을 처리할 때 다른 작업이 끝남을 기다리지 않고 비동기 방식으로 동작
        - Event-Driven 구조 동작 방식
            - Nginx 는 요청에 대한 작업을 처리할 때, CPU 가 관여하지 않는 작업(I/O, socket read/write)을 하면 이거는 스레드가 작업 하지 않고 이벤트 핸들러라는 곳으로 보내 작업한다.
            - 이벤트 핸들러는 작업을 마치게 되면 작업이 완료된 순서대로 큐에 보관
            - 매번 이벤트 루프가 큐를 확인하면서 완료된 작업이 있는지 확인
            - 큐에 있는 값을 응답
* vs Apache
    - Apache : 멀티 프로세스 모듈(MPM) 방식
    - PreFork MPM (다중 프로세스 방식)
        - Client 요청에 대해 자식 프로세스를 생성하여 처리
        - default
        - 하나의 자식 프로세스당 하나의 스레드를 갖는다. (최대 1024개)
        - 스레드간 메모리 공유 x -> 독립적이기에 안정적이지만, 메모리 소모가 크다
    - Worker MPM (멀티 프로세스-스레드 방식)
        - PreFork 보다 메모리 사용량이 적고 동시접속자가 많은 사이트에 사용
        - 각 프로세스의 스레드를 생성해 처리하는 구조
        - 스레드 간 메모리 공유가 가능
        - 프로세스 당 최대 64개의 스레드 처리가 가능 -> 각 스레드는 하나의 연결만을 부여 받음
* 사용 이유
    - 앞단의 NginX
        - 로드 밸랜서 역할
        - 들어오는 요청을 api 서버 80 포트로 RoundRobin 방식으로 전달
    - 뒷단의 NginX
        - blue green 무중단 배포 역할
        - 8080 서버가 서비스되는 도중 코드의 변화가 발생하면 8081 서버를 빌드한 후 실행시킨다.
        - 8081 서버를 헬스체크한 후에 성공적으로 실행이 완료되면 서비스 되던 8080 서버를 죽이고 NginX 의 80포트가 바라보는 포트를 8081 서버로 변경해주어 서비스의 안전성을 높임
* 로드 밸런싱 서비스를 하지않고 NginX 로 로드 밸런싱을 한 이유?
    - 로드 밸런싱이라는 기술을 듣기만 하다가 적용해본적이 처음이라서 직접 구축하면서 동작과정을 눈으로 확인하고 싶었다.
* vs DNS RoundRobin 로드 밸런싱
    - 웹 서버에서 사용할 경우 사이트에 접속하는 사용자가 도메인 주소를 브라우저에 입력하면 DNS 는 도메인에 등록된 여러 개의 IP 리스트 중에서 라운드 로빈 방식으로 사용자에게 IP 를 리턴하여 알려주어야함.
    - 사이트에 접속하는 사용자는 알게 모르게 여러 개의 웹 서버에 나뉘어 접속하게 되면서 서버의 부하가 분산되는 방식
    - 단점
        - 로드 밸런싱 전용의 하드웨어나 소프트웨와는 달리 health Check 에 대한 대안이 없다
        - 즉, 특정 웹 서버에 문제가 생겨 서비스를 못한다고 하더라도 DNS 는 이를 알 방법이 없어 고 가용성 용도로는 부적합하다.
            - 이중화란?
                - 운영중인 서비스의 안전성을 위해 각종 자원을 이중 또는 그 이상으로 구성하는 것을 말한다.
                - 즉, 하나의 서비스에서 장애가 발생하는 경우 다른 서버를 통해 지속적으로 서비스가 가능하게한다.
    - 결론
        - NginX 를 사용하면 서버 이중화가 가능해서 문제가 발생해도 standby 되어있는 로드밸런싱을 활성화 시키는 방법을 사용할 수 있는데 DNS RR 은 불가능하다.
* Health Check
    - L4 : TCP 3-handshake
    - L7 : TCP 3-handshake + HTTP 통신

## 무중단 배포 구현 및 종류
* 간단한 동작 과정
    - Docker 와 Jenkins 를 사용하여 구현
    - DockerFile 을 작성하고 Jenkins 에서 깃허브를 통해 해당 파일을 실행
    - 작성된 DockerFile 은 도커 로그인 후 도커 빌드 명령어를 통해 도커 이미지를 만들어서 도커 허브에 push 한다.
    - 마지막으로 DockerFile 에서 해당 EC2 인스턴스로 접근하여 해당 EC2 인스턴스에 작성된 쉘 스크립트 파일을 시작하는 것으로 진행한다.
* EC2 인스턴스에 nginx 설정
    - 먼저 nginx 설치를 한다. -> sudo yum install nginx
    - nginx 실행 -> sudo service nginx start
    - /etc/nginx/conf.d/ 경로에 service-url.inc 파일울 만들어서 set $service_url http://localhost:808x 를 적는다.
    - 이렇게하고 /etc/nginx/sites-available/ 경로에 default 파일안에 proxy_pass $service_url 작성
    - 이제 EC2 인스턴스에 쉘 스크립트 파일을 작성한다.
    - 도커 로그인 후 도커 허브에서 이전에 push 한 이미지를 pull 받는다.
    - 블루랑 그린에 해당하는 포트 번호를 할당한다 블루는 8080 그린은 8081
    - 그 다음에 현재 실행중이 아닌 색을 도커 런 한다.
    - 헬스 체크 후 실행이 정상적으로 되면 작성한 service_url 을 현재 실행한 포트로 바꾼다.
    - 기존에 실행 중이던 컨테이너를 도커 스탑 도커 rm 명령어로 제거하고 엔진엑스 리로드로 다시 실행한다.
* 롤링 배포
    - 인스턴스 내에서 새 버전을 점진적으로 교체하는 것으로 무중단 배포의 가장 기본적인 방식
    - 서비스 중인 서버 한 대를 제외시키고 그 자리에 새 버전의 서버를 추가한다.
    - 단점
        - 서버 수의 제약이 있을 경우 유용하나 배포 중 인스턴스 수가 감소 되므로 서버 처리 용량을 미리 고려해야한다.
        - 구버전과 신버전이 공존하는 상황이 발생할 수 있다.
          ![images](https://t1.daumcdn.net/cfile/tistory/99143F435C87397A09)
* 무중단 배포
    - 구버전에서 신버전으로 일제히 전환하는 전략
    - 구버전과 신버전의 서버들을 동시에 나란히 구성하고 배포 시점이 되면 트래픽을 일제히 전환시킨다.
    - 장점
        - 운영 환경에 영향을 주지 않고 실제 서비스 환경에서 테스트가 가능하다.
        - 예를 들어, 구버전과 신버전 모두 구성하고 포트를 다르게 주거나 내부 트래픽일 경우 신버전으로 접근하도록 설정하여 테스트를 진행할 수 있다.
    - 단점
        - 시스템 자원이 두 배로 필요하다.
* 카나리
    - 위험을 빠르게 감지하는 배포기법
    - 구버전과 신버전의 서버들을 구성하고 일부 트래픽을 신버전으로 분산하면서 오류를 검출한다.
    - 분산 후 결과에 따라 신버전으로 대체할 수 있고, 다시 구버전으로 돌아갈 수도 있다.
      ![images](https://t1.daumcdn.net/cfile/tistory/99E6E74C5C8737EC0E)